{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting JSAnimation\n",
      "  Downloading JSAnimation-0.1.tar.gz (8.9 kB)\n",
      "Building wheels for collected packages: JSAnimation\n",
      "  Building wheel for JSAnimation (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for JSAnimation: filename=JSAnimation-0.1-py3-none-any.whl size=11425 sha256=44403a836de11feeb4aee9bd4881cdf7ba22218add04d5007de14d89a6205aee\n",
      "  Stored in directory: /home/pemfir/.cache/pip/wheels/b2/85/7b/da07ebc1e3987743ee5f0fe6be2bd55fb45698f8ea91622691\n",
      "Successfully built JSAnimation\n",
      "Installing collected packages: JSAnimation\n",
      "Successfully installed JSAnimation-0.1\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# install package for displaying animation\n",
    "!pip install JSAnimation\n",
    "\n",
    "# custom utilies for displaying animation, collecting rollouts and more\n",
    "import pong_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check which device is being used. \n",
    "# I recommend disabling gpu until you've made sure that the code runs\n",
    "device = pong_utils.device\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "# render ai gym environment\n",
    "import gym\n",
    "import time\n",
    "\n",
    "# PongDeterministic does not contain random frameskip\n",
    "# so is faster to train than the vanilla Pong-v4 environment\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())\n",
    "\n",
    "# we will only use the actions 'RIGHTFIRE' = 4 and 'LEFTFIRE\" = 5\n",
    "# the 'FIRE' part ensures that the game starts again after losing a life\n",
    "# the actions are hard-coded in pong_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show what a preprocessed image looks like\n",
    "env.reset()\n",
    "_, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _ = env.step(1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "\n",
    "## Exercise 1: Implement your policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# set up a convolutional neural net\n",
    "# the output is the probability of moving right\n",
    "# P(left) = 1-P(right)\n",
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        \n",
    "    ########\n",
    "    ## \n",
    "    ## Modify your neural network\n",
    "    ##\n",
    "    ########\n",
    "        \n",
    "        # 80x80 to outputsize x outputsize\n",
    "        # outputsize = (inputsize - kernel_size + stride)/stride \n",
    "        # (round up if not an integer)\n",
    "\n",
    "        # output = 20x20 here\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=4, stride=4)\n",
    "        self.size=1*20*20\n",
    "        \n",
    "        # 1 fully connected layer\n",
    "        self.fc = nn.Linear(self.size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "    ########\n",
    "    ## \n",
    "    ## Modify your neural network\n",
    "    ##\n",
    "    ########\n",
    "    \n",
    "        x = F.relu(self.conv(x))\n",
    "        # flatten the tensor\n",
    "        x = x.view(-1,self.size)\n",
    "        return self.sig(self.fc(x))\n",
    "\n",
    "\n",
    "# run your own policy!\n",
    "# policy=Policy().to(device)\n",
    "policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game visualization\n",
    "pong_utils contain a play function given the environment and a policy. An optional preprocess function can be supplied. Here we define a function that plays a game and shows learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pemfir/anaconda3/envs/unity/lib/python3.6/site-packages/JSAnimation/html_writer.py:282: MatplotlibDeprecationWarning: \n",
      "The 'clear_temp' parameter of setup() was deprecated in Matplotlib 3.3 and will be removed two minor releases later. If any parameter follows 'clear_temp', they should be passed as keyword, not positionally.\n",
      "  frame_prefix, clear_temp=False)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HTMLWriter' object has no attribute '_temp_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d3702a4fab9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpong_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# try to add the option \"preprocess=pong_utils.preprocess_single\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# to see what the agent sees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/pemfir/Data/classes/computer_vision_book/deep-reinforcement-learning/Pong_reinforce/pong_utils.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(env, policy, time, preprocess, nrand)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0manimate_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/pemfir/Data/classes/computer_vision_book/deep-reinforcement-learning/Pong_reinforce/pong_utils.py\u001b[0m in \u001b[0;36manimate_frames\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     47\u001b[0m         lambda x: patch.set_data(frames[x]), frames = len(frames), interval=30)\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'once'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# play a game and display the animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[0;34m(anim, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[0;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[1;32m     74\u001b[0m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[1;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                                  default_mode=default_mode))\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                         \u001b[0mprogress_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                         \u001b[0mframe_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# Call run here now that all frame grabbing is done. All temp files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# are available to be assembled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mMovieWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Will call clean-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unity/lib/python3.6/site-packages/JSAnimation/html_writer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJS_INCLUDE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             of.write(DISPLAY_TEMPLATE.format(id=self.new_id(),\n\u001b[0;32m--> 323\u001b[0;31m                                              \u001b[0mNframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m                                              \u001b[0mfill_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                                              \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HTMLWriter' object has no attribute '_temp_names'"
     ]
    }
   ],
   "source": [
    "pong_utils.play(env, policy, time=200) \n",
    "# try to add the option \"preprocess=pong_utils.preprocess_single\"\n",
    "# to see what the agent sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "Here you will define key functions for training. \n",
    "\n",
    "## Exercise 2: write your own function for training\n",
    "(what I call scalar function is the same as policy_loss up to a negative sign)\n",
    "\n",
    "### PPO\n",
    "Later on, you'll implement the PPO algorithm as well, and the scalar function is given by\n",
    "$\\frac{1}{T}\\sum^T_t \\min\\left\\{R_{t}^{\\rm future}\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)},R_{t}^{\\rm future}{\\rm clip}_{\\epsilon}\\!\\left(\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)}\\right)\\right\\}$\n",
    "\n",
    "the ${\\rm clip}_\\epsilon$ function is implemented in pytorch as ```torch.clamp(ratio, 1-epsilon, 1+epsilon)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "\n",
    "    ########\n",
    "    ## \n",
    "    ## WRITE YOUR OWN CODE HERE\n",
    "    ##\n",
    "    ########\n",
    "    \n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "\n",
    "    # convert states to policy (or probability)\n",
    "    new_probs = pong_utils.states_to_prob(policy, states)\n",
    "    new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "\n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # prevents policy to become exactly 0 or 1 helps exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10)+ \\\n",
    "        (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "\n",
    "    return torch.mean(beta*entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We are now ready to train our policy!\n",
    "WARNING: make sure to turn on GPU, which also enables multicore processing. It may take up to 45 minutes even with GPU enabled, otherwise it will take much longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from parallelEnv import parallelEnv\n",
    "import numpy as np\n",
    "# keep track of how long training takes\n",
    "# WARNING: running through all 800 episodes will take 30-45 minutes\n",
    "\n",
    "# training loop max iterations\n",
    "episode = 500\n",
    "\n",
    "# widget bar to display progress\n",
    "!pip install progressbar\n",
    "import progressbar as pb\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "\n",
    "envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "tmax = 320\n",
    "SGD_epoch = 4\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = \\\n",
    "        pong_utils.collect_trajectories(envs, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "\n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        \n",
    "        # uncomment to utilize your own clipped function!\n",
    "        # L = -clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "\n",
    "        L = -pong_utils.clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                                          epsilon=epsilon, beta=beta)\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong_utils.play(env, policy, time=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your policy!\n",
    "torch.save(policy, 'PPO.policy')\n",
    "\n",
    "# load policy if needed\n",
    "# policy = torch.load('PPO.policy')\n",
    "\n",
    "# try and test out the solution \n",
    "# make sure GPU is enabled, otherwise loading will fail\n",
    "# (the PPO verion can win more often than not)!\n",
    "#\n",
    "# policy_solution = torch.load('PPO_solution.policy')\n",
    "# pong_utils.play(env, policy_solution, time=2000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
